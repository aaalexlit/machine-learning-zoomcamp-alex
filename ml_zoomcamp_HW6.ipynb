{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the California Housing Prices from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "```\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting housing prices (column `'median_house_value'`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘housing.csv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import  RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preparing the dataset \n",
    "\n",
    "For this homework, we only want to use a subset of data. This is the same subset we used in homework #2.\n",
    "But in contrast to homework #2, we are going to use all columns of the dataset.\n",
    "\n",
    "First, keep only the records where `ocean_proximity` is either `'<1H OCEAN'` or `'INLAND'`\n",
    "\n",
    "Preparation:\n",
    "\n",
    "* Fill missing values with zeros.\n",
    "* Apply the log transform to `median_house_value`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "df = df[(df.ocean_proximity == '<1H OCEAN') | (df.ocean_proximity == 'INLAND')]\n",
    "df = df.fillna(0)\n",
    "y = np.log1p(df.median_house_value.values)\n",
    "del df[\"median_house_value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9411, 3138, 3138, 3138)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train, df_test, y_full_train, y_test = train_test_split(df, y, test_size=0.2, random_state=1)\n",
    "df_train, df_val, y_train, y_val = train_test_split(df_full_train, y_full_train, test_size=0.25, random_state=1)\n",
    "len(df_train), len(df_val), len(df_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "test_dict = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `median_house_value` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `ocean_proximity`\n",
    "* `total_rooms`\n",
    "* `latitude`\n",
    "* `population`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- ocean_proximity=<1H OCEAN <= 0.50\n",
      "|   |--- value: [11.61]\n",
      "|--- ocean_proximity=<1H OCEAN >  0.50\n",
      "|   |--- value: [12.30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=1)\n",
    "dtr.fit(X_train, y_train)\n",
    "from sklearn.tree import export_text\n",
    "print(export_text(dtr, feature_names=dv.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.045\n",
    "* 0.245\n",
    "* 0.545\n",
    "* 0.845\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.245"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "mean_squared_error(y_val, y_pred, squared=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "Consider 3 decimal places for retrieving the answer.\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 50\n",
    "- 160\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values,\n",
    "  * try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "  * calculate the mean RMSE \n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`, using the mean RMSE?\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorithm, it finds the best split. \n",
    "When doing it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the important features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parameters:\n",
    "  * `n_estimators=10`,\n",
    "  * `max_depth=20`,\n",
    "  * `random_state=1`,\n",
    "  * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `total_rooms`\n",
    "* `median_income`\n",
    "* `total_bedrooms`\n",
    "* `longitude`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
