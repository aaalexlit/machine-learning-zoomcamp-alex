{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44735bcf-7563-42f3-aeb5-9f43390f1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30da6fd0-5c25-4fa8-b396-0c5ba964e9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac5ff6e-71b1-4f74-8833-db0aadf7b706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘clothing-model.h5’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636c836e-5fcd-4ac0-8bc6-b7b0906876ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3083a63-cc17-4080-ab4f-9283a6d2ab63",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0a39acf-3d86-465e-8a2a-899755bf8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('clothing-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3deaa2f-a747-4fff-b1f8-67477427de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9aa91ec-778c-4406-9b99-dc29bd8d77d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘pants.jpg’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget -nc http://bit.ly/mlbookcamp-pants -O pants.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f36b587e-5801-435c-99d8-024e9a997927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50d37b70-8658-46f9-81a1-2e7a38d829df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('pants.jpg', target_size=(299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7c075f8-be4d-4a5d-9eb8-361588466342",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc33099-6ae1-477b-9576-476e362a201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_input(X[tf.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d548662c-052e-4e81-a81c-a1920251d428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 359ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39b7f6b8-b422-4167-b214-2b21b6bc8cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.879864 , -4.756312 , -2.3595333, -1.0892622,  9.903783 ,\n",
       "        -2.82618  , -3.64831  ,  3.241155 , -2.6120963, -4.852036 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac0c9555-87be-4849-b3ac-d909bbe6f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6257127b-2b50-4b35-8320-f142383a7ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': -1.879864,\n",
       " 'hat': -4.756312,\n",
       " 'longsleeve': -2.3595333,\n",
       " 'outwear': -1.0892622,\n",
       " 'pants': 9.903783,\n",
       " 'shirt': -2.82618,\n",
       " 'shoes': -3.64831,\n",
       " 'shorts': 3.241155,\n",
       " 'skirt': -2.6120963,\n",
       " 't-shirt': -4.852036}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, preds[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651907ed-c009-4e7e-9b3f-5a2ac36049a4",
   "metadata": {},
   "source": [
    "# Convert Keras to TF-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d25718e-904a-48d0-b6b3-5284a8579da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/xp/nfq4xfg90wzfc3w1r68x1hkr0000gp/T/tmpsl__082a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/xp/nfq4xfg90wzfc3w1r68x1hkr0000gp/T/tmpsl__082a/assets\n",
      "2023-11-25 06:21:12.569745: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-25 06:21:12.569757: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-25 06:21:12.569893: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/xp/nfq4xfg90wzfc3w1r68x1hkr0000gp/T/tmpsl__082a\n",
      "2023-11-25 06:21:12.579876: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-25 06:21:12.579884: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/xp/nfq4xfg90wzfc3w1r68x1hkr0000gp/T/tmpsl__082a\n",
      "2023-11-25 06:21:12.607744: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-25 06:21:12.901235: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/xp/nfq4xfg90wzfc3w1r68x1hkr0000gp/T/tmpsl__082a\n",
      "2023-11-25 06:21:12.980990: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 411097 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 125, Total Ops 232, % non-converted = 53.88 %\n",
      " * 125 ARITH ops\n",
      "\n",
      "- arith.constant:  125 occurrences  (f32: 124, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 12)\n",
      "  (f32: 40)\n",
      "  (f32: 34)\n",
      "  (f32: 2)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 11)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('clothing-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaeabc47-f4f8-482e-bc94-6e27830472b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2378a988-795e-4283-a7b0-903d947a4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path='clothing-model.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11738d0a-69c9-4fd8-9097-cf34e6b1c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serving_default': {'inputs': ['input_8'], 'outputs': ['dense_7']}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_signature_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98a28965-9355-4952-adc5-832854761ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lite = interpreter.get_signature_runner('serving_default')(input_8=X)['dense_7']\n",
    "score_lite = tf.nn.softmax(predictions_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f853402d-a273-4f4c-89df-3bca733f4bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dress': 7.6182255e-06,\n",
       " 'hat': 4.2917034e-07,\n",
       " 'longsleeve': 4.7156077e-06,\n",
       " 'outwear': 1.6796124e-05,\n",
       " 'pants': 0.99868613,\n",
       " 'shirt': 2.957161e-06,\n",
       " 'shoes': 1.299657e-06,\n",
       " 'shorts': 0.0012761031,\n",
       " 'skirt': 3.6631166e-06,\n",
       " 't-shirt': 3.899927e-07}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(classes, score_lite.numpy()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d56eb1a-abfe-47ad-8d7e-841e33ba6743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to pants with a 99.87 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(classes[np.argmax(score_lite)], 100 * np.max(score_lite))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75f854fc-7061-4ea1-8b0f-b0c5f50a53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.861023e-06\n"
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(preds - predictions_lite)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f5fa4d-15ec-46b5-b07f-41fed6260587",
   "metadata": {},
   "source": [
    "### Check how to set the inputs and where to get the outputs from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c62b4b40-c0f0-43d4-a266-426ba52ebe78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_input_8:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 299, 299,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 299, 299,   3], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b00aba62-7844-4ed1-a1be-29d78fa5e724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 229,\n",
       "  'shape': array([ 1, 10], dtype=int32),\n",
       "  'shape_signature': array([-1, 10], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "661a7969-ae53-489f-838c-965b40a8f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c25a6c2-a808-4c89-9eed-f3e45a50a571",
   "metadata": {},
   "source": [
    "### Initialize the network with the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "268388ec-cde3-4898-99f7-adc3978fd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bac0e16d-bf5a-4d3e-9ba3-1abaf3f36136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize calculations\n",
    "\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61842424-60b5-4677-bf0f-3c3a4ff95eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "\n",
    "lite_preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589dd79-2369-4391-88f8-cc1b4d6099bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
