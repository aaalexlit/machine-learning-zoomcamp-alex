{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9385b4-0cd6-433e-9475-3a7eb4140639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T22:01:27.866642Z",
     "iopub.status.busy": "2023-11-20T22:01:27.866240Z",
     "iopub.status.idle": "2023-11-20T22:01:27.870699Z",
     "shell.execute_reply": "2023-11-20T22:01:27.869916Z",
     "shell.execute_reply.started": "2023-11-20T22:01:27.866572Z"
    }
   },
   "source": [
    "# Download the dataset\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this homework, we'll build a model for predicting if we have an image of a bee or a wasp. \n",
    "For this, we will use the \"Bee or Wasp?\" dataset that was obtained from [Kaggle](https://www.kaggle.com/datasets/jerzydziewierz/bee-vs-wasp) and slightly rebuilt. \n",
    "\n",
    "You can download the dataset for this homework from [here](https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip):\n",
    "\n",
    "```bash\n",
    "wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n",
    "unzip data.zip\n",
    "```\n",
    "\n",
    "In the lectures we saw how to use a pre-trained neural network. In the homework, we'll train a much smaller model from scratch. \n",
    "\n",
    "> **Note:** you will need an environment with a GPU for this homework. We recommend to use [Saturn Cloud](https://bit.ly/saturn-mlzoomcamp). \n",
    "> You can also use a computer without a GPU (e.g. your laptop), but it will be slower.\n",
    "\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "The dataset contains around 2500 images of bees and around 2100 images of wasps. \n",
    "\n",
    "The dataset contains separate folders for training and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84a4ef-cdf3-4694-9668-7e0e035acec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/bee-wasp-data/data.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909dc982-efc8-41d2-b369-7534d62bac87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T06:42:27.977057Z",
     "iopub.status.busy": "2023-11-21T06:42:27.976682Z",
     "iopub.status.idle": "2023-11-21T06:42:29.102049Z",
     "shell.execute_reply": "2023-11-21T06:42:29.101353Z",
     "shell.execute_reply.started": "2023-11-21T06:42:27.977029Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n",
      "rm: cannot remove 'data.zip': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip\n",
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a713771-df50-48ee-a8a5-38f4e2eb4a99",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe082cc-da45-4b04-b5a7-54445631b5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:27:25.702170Z",
     "iopub.status.busy": "2023-11-21T21:27:25.701758Z",
     "iopub.status.idle": "2023-11-21T21:27:25.706834Z",
     "shell.execute_reply": "2023-11-21T21:27:25.705855Z",
     "shell.execute_reply.started": "2023-11-21T21:27:25.702140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4c87e-c9ec-4c3d-a3e6-34d2d2463440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T07:07:41.483323Z",
     "iopub.status.busy": "2023-11-21T07:07:41.482932Z",
     "iopub.status.idle": "2023-11-21T07:07:41.486518Z",
     "shell.execute_reply": "2023-11-21T07:07:41.485793Z",
     "shell.execute_reply.started": "2023-11-21T07:07:41.483296Z"
    }
   },
   "source": [
    "# Model\n",
    "\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "* The shape for input should be `(150, 150, 3)`\n",
    "* Next, create a convolutional layer ([`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)):\n",
    "    * Use 32 filters\n",
    "    * Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    * Use `'relu'` as activation \n",
    "* Reduce the size of the feature map with max pooling ([`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/))\n",
    "    * Set the pooling size to `(2, 2)`\n",
    "* Turn the multi-dimensional result into vectors using a [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/) layer\n",
    "* Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "* Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    * The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use [`SGD`](https://keras.io/api/optimizers/sgd/) with the following parameters:\n",
    "\n",
    "* `SGD(lr=0.002, momentum=0.8)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c5d6f8-5ebe-45d4-b775-c1be6cf3fc06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:20:53.575619Z",
     "iopub.status.busy": "2023-11-21T21:20:53.574898Z",
     "iopub.status.idle": "2023-11-21T21:20:53.582990Z",
     "shell.execute_reply": "2023-11-21T21:20:53.582236Z",
     "shell.execute_reply.started": "2023-11-21T21:20:53.575577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_model(size=150):\n",
    "    \n",
    "    inputs = keras.Input(shape=(size, size, 3))\n",
    "    # when using image_dataset_from_directory we need to include rescaling layer\n",
    "    rescaled = layers.Rescaling(1./255)(inputs)\n",
    "    conv2d = layers.Conv2D(filters=32, kernel_size=3, activation='relu')(rescaled)\n",
    "    pooled = layers.MaxPooling2D()(conv2d)\n",
    "    flattened = layers.Flatten()(pooled)\n",
    "    \n",
    "    fully_connected = layers.Dense(units=64, activation='relu')(flattened)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation=keras.activations.sigmoid)(fully_connected)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(lr=0.002, momentum=0.8)\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e402114-2b8c-4be5-bad1-dccdca2638c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:20:55.409179Z",
     "iopub.status.busy": "2023-11-21T21:20:55.408761Z",
     "iopub.status.idle": "2023-11-21T21:20:56.548910Z",
     "shell.execute_reply": "2023-11-21T21:20:56.546729Z",
     "shell.execute_reply.started": "2023-11-21T21:20:55.409152Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 21:20:55.513419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:55.520244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:55.520901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:55.521863: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 21:20:55.522278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:55.522934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:55.523477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:56.208158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:56.208786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:56.209323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-21 21:20:56.209855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13795 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc2337-73e3-4416-bded-ce2c3855cbae",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "* `mean squared error`\n",
    "* `binary crossentropy`\n",
    "* `categorical crossentropy`\n",
    "* `cosine similarity`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da314340-5ad1-4917-a592-18f4a8268aac",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the number of parameters in the convolutional layer of our model? You can use the `summary` method for that. \n",
    "\n",
    "* 1 \n",
    "* 65\n",
    "* 896\n",
    "* 11214912\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b90ca440-1208-4d28-86ec-7172c927214e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:20:59.623656Z",
     "iopub.status.busy": "2023-11-21T21:20:59.623229Z",
     "iopub.status.idle": "2023-11-21T21:20:59.642870Z",
     "shell.execute_reply": "2023-11-21T21:20:59.642041Z",
     "shell.execute_reply.started": "2023-11-21T21:20:59.623628Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d1e0ab-b3cf-4f58-a199-530daaa9e2bd",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and test sets:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "* We don't need to do any additional pre-processing for the images.\n",
    "* When reading the data from train/test directories, check the `class_mode` parameter. Which value should it be for a binary classification problem?\n",
    "* Use `batch_size=20`\n",
    "* Use `shuffle=True` for both training and test sets. \n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed62bce1-5c5e-4b13-8381-7da13581420d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:50:17.302335Z",
     "iopub.status.busy": "2023-11-21T21:50:17.301918Z",
     "iopub.status.idle": "2023-11-21T21:50:17.307394Z",
     "shell.execute_reply": "2023-11-21T21:50:17.306464Z",
     "shell.execute_reply.started": "2023-11-21T21:50:17.302309Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_ds():\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        'data/train/',\n",
    "        # The default one is 32 so set to None since we will batch later\n",
    "        batch_size=None,\n",
    "        image_size=(150, 150),\n",
    "        label_mode='binary',\n",
    "    )\n",
    "\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        'data/test/',\n",
    "        batch_size=None,\n",
    "        image_size=(150, 150),\n",
    "        label_mode='binary',\n",
    "    )\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76a40f1-6d98-4012-8525-d45709db6462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:23:53.153160Z",
     "iopub.status.busy": "2023-11-21T21:23:53.152746Z",
     "iopub.status.idle": "2023-11-21T21:23:53.157778Z",
     "shell.execute_reply": "2023-11-21T21:23:53.157045Z",
     "shell.execute_reply.started": "2023-11-21T21:23:53.153133Z"
    }
   },
   "outputs": [],
   "source": [
    "def configure_for_performance(ds, batch_size=20, data_aug_fn=None):\n",
    "    ds = ds.cache()\n",
    "    if data_aug_fn:\n",
    "        ds = ds.map(data_aug_fn, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a82148-4f44-4006-835d-bca67d46402d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:50:35.532161Z",
     "iopub.status.busy": "2023-11-21T21:50:35.531747Z",
     "iopub.status.idle": "2023-11-21T21:50:35.783183Z",
     "shell.execute_reply": "2023-11-21T21:50:35.782406Z",
     "shell.execute_reply.started": "2023-11-21T21:50:35.532135Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3681 files belonging to 2 classes.\n",
      "Found 918 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = read_ds()\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc89a223-b6fd-4758-998d-769a7be86fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:25:51.933067Z",
     "iopub.status.busy": "2023-11-21T21:25:51.932652Z",
     "iopub.status.idle": "2023-11-21T21:26:19.788688Z",
     "shell.execute_reply": "2023-11-21T21:26:19.787984Z",
     "shell.execute_reply.started": "2023-11-21T21:25:51.933040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 21:25:53.689979: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2023-11-21 21:25:54.395173: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-21 21:25:54.395684: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-21 21:25:54.395724: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-11-21 21:25:54.396244: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-21 21:25:54.396336: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 7s 19ms/step - loss: 0.6522 - accuracy: 0.6061 - val_loss: 0.6043 - val_accuracy: 0.6242\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.5753 - accuracy: 0.6971 - val_loss: 0.5455 - val_accuracy: 0.7331\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.5325 - accuracy: 0.7419 - val_loss: 0.5397 - val_accuracy: 0.7266\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.5087 - accuracy: 0.7637 - val_loss: 0.5325 - val_accuracy: 0.7309\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.4900 - accuracy: 0.7770 - val_loss: 0.5186 - val_accuracy: 0.7560\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.4630 - accuracy: 0.7908 - val_loss: 0.5129 - val_accuracy: 0.7603\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 2s 12ms/step - loss: 0.4334 - accuracy: 0.8052 - val_loss: 0.5065 - val_accuracy: 0.7647\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.4017 - accuracy: 0.8250 - val_loss: 0.5072 - val_accuracy: 0.7593\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.3701 - accuracy: 0.8457 - val_loss: 0.5153 - val_accuracy: 0.7440\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 2s 13ms/step - loss: 0.3365 - accuracy: 0.8685 - val_loss: 0.5205 - val_accuracy: 0.7495\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    epochs=10, \n",
    "                    validation_data=val_ds,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee2052c-2e38-4c85-b9c4-b3a0ba078470",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "* 0.20\n",
    "* 0.40\n",
    "* 0.60\n",
    "* 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c0b182f-5d55-4c00-a7a3-40816f614daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:27:35.508860Z",
     "iopub.status.busy": "2023-11-21T21:27:35.508443Z",
     "iopub.status.idle": "2023-11-21T21:27:35.514641Z",
     "shell.execute_reply": "2023-11-21T21:27:35.513707Z",
     "shell.execute_reply.started": "2023-11-21T21:27:35.508833Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7838902473449707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91063756-284a-421d-a9e5-35704fd35448",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "* 0.031\n",
    "* 0.061\n",
    "* 0.091\n",
    "* 0.131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "994aefa7-5169-4936-9fc1-d59da08ebc7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:28:58.853645Z",
     "iopub.status.busy": "2023-11-21T21:28:58.853224Z",
     "iopub.status.idle": "2023-11-21T21:28:58.859312Z",
     "shell.execute_reply": "2023-11-21T21:28:58.858389Z",
     "shell.execute_reply.started": "2023-11-21T21:28:58.853618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09140642920399505"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc51df4-a751-49d2-ade6-59c79e79a784",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations. \n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "* `rotation_range=50,`\n",
    "* `width_shift_range=0.1,`\n",
    "* `height_shift_range=0.1,`\n",
    "* `zoom_range=0.1,`\n",
    "* `horizontal_flip=True,`\n",
    "* `fill_mode='nearest'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f82007c6-f1ad-483c-9dd8-3c52fef92912",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:58:10.917192Z",
     "iopub.status.busy": "2023-11-21T21:58:10.916785Z",
     "iopub.status.idle": "2023-11-21T21:58:10.936946Z",
     "shell.execute_reply": "2023-11-21T21:58:10.936262Z",
     "shell.execute_reply.started": "2023-11-21T21:58:10.917163Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(factor=0.28, fill_mode='nearest'),\n",
    "    layers.RandomZoom(height_factor=0.1, fill_mode='nearest'),\n",
    "    layers.RandomWidth(factor=0.1, interpolation='nearest'),\n",
    "    layers.RandomHeight(factor=0.1, interpolation='nearest'),\n",
    "    layers.Resizing(150, 150)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69fc5788-095b-458b-9f27-683658b2385c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:58:11.617194Z",
     "iopub.status.busy": "2023-11-21T21:58:11.616781Z",
     "iopub.status.idle": "2023-11-21T21:58:12.221395Z",
     "shell.execute_reply": "2023-11-21T21:58:12.220650Z",
     "shell.execute_reply.started": "2023-11-21T21:58:11.617167Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3681 files belonging to 2 classes.\n",
      "Found 918 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds = read_ds()\n",
    "train_ds = configure_for_performance(train_ds, data_aug_fn=lambda img, label: (data_augmentation(img), label))\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1eb9d-1cba-431a-a447-c0ceaaf9c61c",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "> **Note:** make sure you don't re-create the model - we want to continue training the model\n",
    "we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "* 0.18\n",
    "* 0.48\n",
    "* 0.78\n",
    "* 0.108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0208f484-8ee5-47d2-b68d-861c2a1997fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T21:58:13.078608Z",
     "iopub.status.busy": "2023-11-21T21:58:13.078175Z",
     "iopub.status.idle": "2023-11-21T21:59:46.103603Z",
     "shell.execute_reply": "2023-11-21T21:59:46.102864Z",
     "shell.execute_reply.started": "2023-11-21T21:58:13.078578Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 11s 56ms/step - loss: 0.4976 - accuracy: 0.7702 - val_loss: 0.5755 - val_accuracy: 0.7320\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.5053 - accuracy: 0.7607 - val_loss: 0.4830 - val_accuracy: 0.7712\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.4891 - accuracy: 0.7753 - val_loss: 0.5067 - val_accuracy: 0.7669\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.4887 - accuracy: 0.7732 - val_loss: 0.5226 - val_accuracy: 0.7516\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.5063 - accuracy: 0.7577 - val_loss: 0.4863 - val_accuracy: 0.7691\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.5041 - accuracy: 0.7675 - val_loss: 0.5202 - val_accuracy: 0.7571\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.4886 - accuracy: 0.7767 - val_loss: 0.5005 - val_accuracy: 0.7658\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.4830 - accuracy: 0.7767 - val_loss: 0.4931 - val_accuracy: 0.7625\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 9s 49ms/step - loss: 0.4764 - accuracy: 0.7810 - val_loss: 0.5165 - val_accuracy: 0.7516\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 9s 48ms/step - loss: 0.5132 - accuracy: 0.7522 - val_loss: 0.6639 - val_accuracy: 0.6917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, \n",
    "                    epochs=10, \n",
    "                    validation_data=val_ds,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda4aa32-ac48-4f2d-8cf9-1a254838b17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T22:00:53.364100Z",
     "iopub.status.busy": "2023-11-21T22:00:53.363675Z",
     "iopub.status.idle": "2023-11-21T22:00:53.369755Z",
     "shell.execute_reply": "2023-11-21T22:00:53.368888Z",
     "shell.execute_reply.started": "2023-11-21T22:00:53.364069Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5268334418535232"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91403d44-b455-4cfa-8187-8e1feba78dc6",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "* 0.38\n",
    "* 0.58\n",
    "* 0.78\n",
    "* 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e366344-4ba1-46e0-8506-16d922a1bd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T22:03:41.943372Z",
     "iopub.status.busy": "2023-11-21T22:03:41.942959Z",
     "iopub.status.idle": "2023-11-21T22:03:41.949052Z",
     "shell.execute_reply": "2023-11-21T22:03:41.948187Z",
     "shell.execute_reply.started": "2023-11-21T22:03:41.943345Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457516431808472"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_accuracy'][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3bb727-5637-48c0-bde0-7091f0bc461e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
