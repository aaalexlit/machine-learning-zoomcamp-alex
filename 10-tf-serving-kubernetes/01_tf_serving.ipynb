{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the model\n",
    "\n",
    "Download the full trained TF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘clothing-model.h5’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to saved_model format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('./clothing-model.h5')\n",
    "\n",
    "tf.saved_model.save(model, 'clothing-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mclothing-model\u001b[0m\n",
      "├── \u001b[1;36massets\u001b[0m\n",
      "├── fingerprint.pb\n",
      "├── saved_model.pb\n",
      "└── \u001b[1;36mvariables\u001b[0m\n",
      "    ├── variables.data-00000-of-00001\n",
      "    └── variables.index\n",
      "\n",
      "3 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "!tree clothing-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lhR clothing-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look on the saved model using tensorflow's built-in utility `saved_model_cli`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['input_8'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 299, 299, 3)\n",
      "      name: serving_default_input_8:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense_7'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 10)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir clothing-model --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to TF serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import tensorflow as tf\n",
    "import json\n",
    " \n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the address and port of the TensorFlow Serving server\n",
    "server_address = 'localhost'\n",
    "server_port = 8500\n",
    "\n",
    "# Create a gRPC channel\n",
    "channel = grpc.insecure_channel(f'{server_address}:{server_port}')\n",
    "\n",
    "# Create a stub for the prediction service\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 127.5\n",
    "    x -= 1\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_img(img):\n",
    "    x = np.array(img.resize((299, 299)), dtype=\"float32\")\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "    X = preprocess_input(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def read_img_from_url(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "\n",
    "    return preprocess_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "\n",
    "X = read_img_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"dress\",\n",
    "    \"hat\",\n",
    "    \"longsleeve\",\n",
    "    \"outwear\",\n",
    "    \"pants\",\n",
    "    \"shirt\",\n",
    "    \"shoes\",\n",
    "    \"shorts\",\n",
    "    \"skirt\",\n",
    "    \"t-shirt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_name = 'input_8'\n",
    "output_tensor_name = 'dense_7'\n",
    "model_name = 'clothing-model'\n",
    "\n",
    "# Create a request object\n",
    "request = predict_pb2.PredictRequest()\n",
    "\n",
    "# Set the model name and input tensor data\n",
    "request.model_spec.name = 'clothing-model'\n",
    "request.model_spec.signature_name = tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "\n",
    "# Serialize the example proto to bytes and set it in the request\n",
    "request.inputs[input_tensor_name].CopyFrom(\n",
    "    tf.make_tensor_proto(X, dtype=tf.float32)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction: {\n",
      "    \"dress\": -1.9792001247406006,\n",
      "    \"hat\": -4.7238240242004395,\n",
      "    \"longsleeve\": -2.130927324295044,\n",
      "    \"outwear\": -1.0491342544555664,\n",
      "    \"pants\": 9.957743644714355,\n",
      "    \"shirt\": -3.027919054031372,\n",
      "    \"shoes\": -3.8510289192199707,\n",
      "    \"shorts\": 3.5252106189727783,\n",
      "    \"skirt\": -2.746251106262207,\n",
      "    \"t-shirt\": -4.712244510650635\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Make the gRPC request and get the response\n",
    "response = stub.Predict(request, timeout=10.0)\n",
    "\n",
    "# Extract and print the result \n",
    "output_data = response.outputs[output_tensor_name].float_val\n",
    "\n",
    "print(f\"Model Prediction: {json.dumps(dict(zip(classes, output_data)), indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test `gateway.py`\n",
    "\n",
    "Run tf_serving docker-compose:\n",
    "\n",
    "```shell\n",
    "docker compose -f docker-compose-tf-serving.yaml up -d\n",
    "```\n",
    "\n",
    "Launch it with \n",
    "```shell\n",
    "python gateway.py\n",
    "```\n",
    "\n",
    "Run a curl\n",
    "```shell\n",
    "curl -X POST 'http://127.0.0.1:8000/predict'  -H 'Content-Type: application/json' -d '{  \n",
    "  \"url\": \"http://bit.ly/mlbookcamp-pants\"\n",
    "}'\n",
    "```\n",
    "\n",
    "or go to the Swagger UI\n",
    "\n",
    "http://127.0.0.1:8000/docs#/default/predict_predict_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
